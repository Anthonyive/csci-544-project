{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cda20d7",
   "metadata": {},
   "source": [
    "### arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cad0a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "data=[]\n",
    "with open('../csci-544-project/data/longformer_arxiv.txt') as f:\n",
    "    text = f.readline()\n",
    "    while text:\n",
    "        json_data = json.loads(text)\n",
    "        data.append(json_data)\n",
    "        text = f.readline()\n",
    "    final_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5deedde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>predicted_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>the short - term periodicities of the daily s...</td>\n",
       "      <td>a new method of the detection of statisticall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>we study the detectability of circular polari...</td>\n",
       "      <td>we investigate the detectability of circular ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>starting from the wkb approximation , a new b...</td>\n",
       "      <td>in the study of barrier penetration in nuclea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>we study a novel class of numerical integrato...</td>\n",
       "      <td>the hybrid monte carlo algorithm ( hmc ) is u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>new methods for obtaining functional equation...</td>\n",
       "      <td>we propose essentially new methods for derivi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>two major advantages of the star detector - u...</td>\n",
       "      <td>the ongoing heavy ion physics program with th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>the alice detector has excellent particle ide...</td>\n",
       "      <td>the alice experiment at the large hadron coll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>erupting filaments are sometimes observed to ...</td>\n",
       "      <td>we describe two events in which the axis of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>the stability , electronic and optical proper...</td>\n",
       "      <td>we theoretically investigate the stability an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>in vivo calcium imaging through microscopes h...</td>\n",
       "      <td>in this paper, we propose an efficient method...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                           abstract  \\\n",
       "0    0   the short - term periodicities of the daily s...   \n",
       "1    1   we study the detectability of circular polari...   \n",
       "2    2   starting from the wkb approximation , a new b...   \n",
       "3    3   we study a novel class of numerical integrato...   \n",
       "4    4   new methods for obtaining functional equation...   \n",
       "..  ..                                                ...   \n",
       "95  95   two major advantages of the star detector - u...   \n",
       "96  96   the alice detector has excellent particle ide...   \n",
       "97  97   erupting filaments are sometimes observed to ...   \n",
       "98  98   the stability , electronic and optical proper...   \n",
       "99  99   in vivo calcium imaging through microscopes h...   \n",
       "\n",
       "                                   predicted_abstract  \n",
       "0    a new method of the detection of statisticall...  \n",
       "1    we investigate the detectability of circular ...  \n",
       "2    in the study of barrier penetration in nuclea...  \n",
       "3    the hybrid monte carlo algorithm ( hmc ) is u...  \n",
       "4    we propose essentially new methods for derivi...  \n",
       "..                                                ...  \n",
       "95   the ongoing heavy ion physics program with th...  \n",
       "96   the alice experiment at the large hadron coll...  \n",
       "97   we describe two events in which the axis of a...  \n",
       "98   we theoretically investigate the stability an...  \n",
       "99   in this paper, we propose an efficient method...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2257a9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using GPT-3 model with arxiv row text\n",
    "import os\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "openai.organization = \"org-dcppzQporJVCl0uhI8Tk67Xo\"\n",
    "openai.api_key = \"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\"\n",
    "engine_list = openai.Engine.list() \n",
    "#openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "output = []\n",
    "#final_output = []\n",
    "for i in tqdm(range(len(final_df))):\n",
    "    try:\n",
    "        tldr_tag = \"\\n tl;dr:\"\n",
    "        text =  str(final_df[\"abstract\"].iloc[i])+ tldr_tag\n",
    "        response = openai.Completion.create(\n",
    "          engine=\"curie\",\n",
    "          prompt=text,\n",
    "          temperature=0.5,\n",
    "          max_tokens=500,\n",
    "          top_p=1,\n",
    "          frequency_penalty=0.2,\n",
    "          presence_penalty=0\n",
    "        )\n",
    "        output.append(response[\"choices\"][0]['text'])\n",
    "    except:# if the token exceed the maximum tokens number in GPT-3 model,then just use first half text\n",
    "        tldr_tag = \"\\n tl;dr:\"\n",
    "        a = final_df[\"abstract\"].iloc[i][:int(len(final_df[\"abstract\"].iloc[i])/2)]\n",
    "        text = a+ tldr_tag\n",
    "        response = openai.Completion.create(\n",
    "          engine=\"curie\",\n",
    "          prompt=text,\n",
    "          temperature=0.5,\n",
    "          max_tokens=500,\n",
    "          top_p=1,\n",
    "          frequency_penalty=0.2,\n",
    "          presence_penalty=0\n",
    "        )\n",
    "        output.append(response[\"choices\"][0]['text'])\n",
    "#final_output.append(output)\n",
    "pred_df = pd.DataFrame()\n",
    "pred_df[\"summary\"] = output \n",
    "pred_df.to_csv(\"arxiv_before_longformer_summary_100.csv\",sep = ' ',index = False,header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "420f576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_metric\n",
    "metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b6cf1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.read_csv(\"arxiv_before_longformer_summary_100.csv\",sep = ' ',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c72c2036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=0.4313522644689784, recall=0.4679212868277528, fmeasure=0.354900276969554), mid=Score(precision=0.49121030914472946, recall=0.5354564689820189, fmeasure=0.3983961309912373), high=Score(precision=0.549473680109072, recall=0.5982452070174479, fmeasure=0.44447665244458245)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=0.2860980524999031, recall=0.33218445683066405, fmeasure=0.2470464990910358), mid=Score(precision=0.3401009543534795, recall=0.4000147118799643, fmeasure=0.29683394682167435), high=Score(precision=0.3942623268286011, recall=0.4745161889631958, fmeasure=0.35154424052198313)),\n",
       " 'rougeL': AggregateScore(low=Score(precision=0.3538032913412862, recall=0.39557624464339985, fmeasure=0.2880500313695473), mid=Score(precision=0.4069084940348759, recall=0.4586126941024754, fmeasure=0.3373684954620597), high=Score(precision=0.46390097988296664, recall=0.5258198872160031, fmeasure=0.3865533217474746)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=0.40391978730980094, recall=0.4446054587387735, fmeasure=0.33384065320391926), mid=Score(precision=0.46357289603842045, recall=0.5076105540360629, fmeasure=0.3779348890651676), high=Score(precision=0.5295529561058367, recall=0.5707035743841585, fmeasure=0.42920638931328653))}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_preds = output[0]\n",
    "fake_labels = final_df['abstract']\n",
    "rouge_raw_before_longformer = metric.compute(predictions=fake_preds, references=fake_labels)\n",
    "rouge_raw_before_longformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2884c3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [04:04<00:00,  2.45s/it]\n"
     ]
    }
   ],
   "source": [
    "# using GPT-3 model with pred of longformer\n",
    "import os\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "openai.organization = \"org-dcppzQporJVCl0uhI8Tk67Xo\"\n",
    "openai.api_key = \"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\"\n",
    "engine_list = openai.Engine.list() \n",
    "#openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "output = []\n",
    "#final_output = []\n",
    "for i in tqdm(range(len(final_df))):\n",
    "    try:\n",
    "        tldr_tag = \"\\n tl;dr:\"\n",
    "        text =  str(final_df[\"predicted_abstract\"].iloc[i])+ tldr_tag\n",
    "        response = openai.Completion.create(\n",
    "          engine=\"curie\",\n",
    "          prompt=text,\n",
    "          temperature=0.5,\n",
    "          max_tokens=500,\n",
    "          top_p=1,\n",
    "          frequency_penalty=0.2,\n",
    "          presence_penalty=0\n",
    "        )\n",
    "        output.append(response[\"choices\"][0]['text'])\n",
    "    except:# if the token exceed the maximum tokens number in GPT-3 model,then just use first half text\n",
    "        tldr_tag = \"\\n tl;dr:\"\n",
    "        a = final_df[\"predicted_abstract\"].iloc[i][:int(len(final_df[\"predicted_abstract\"].iloc[i])/2)]\n",
    "        text = a+ tldr_tag\n",
    "        response = openai.Completion.create(\n",
    "          engine=\"curie\",\n",
    "          prompt=text,\n",
    "          temperature=0.5,\n",
    "          max_tokens=500,\n",
    "          top_p=1,\n",
    "          frequency_penalty=0.2,\n",
    "          presence_penalty=0\n",
    "        )\n",
    "        output.append(response[\"choices\"][0]['text'])\n",
    "#final_output.append(output)\n",
    "pred_df = pd.DataFrame()\n",
    "pred_df[\"summary\"] = output \n",
    "pred_df.to_csv(\"arxiv_after_longformer_summary_100.csv\",sep = ' ',index = False,header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45da7c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_metric\n",
    "metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9deff1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=0.327779479183122, recall=0.32055330689482026, fmeasure=0.2591543326561672), mid=Score(precision=0.36642853522027735, recall=0.36497325520291013, fmeasure=0.2823772424999206), high=Score(precision=0.405390053914228, recall=0.40731721409057836, fmeasure=0.3083257596647505)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=0.10426517998751919, recall=0.10557574760259797, fmeasure=0.08223930190951104), mid=Score(precision=0.12596914621942312, recall=0.12809140183470827, fmeasure=0.09819545764447249), high=Score(precision=0.14852732911928643, recall=0.15301364162959546, fmeasure=0.11769361121775433)),\n",
       " 'rougeL': AggregateScore(low=Score(precision=0.21072676272117755, recall=0.19679792101961854, fmeasure=0.15794987493749013), mid=Score(precision=0.23958273403701585, recall=0.22344457574205623, fmeasure=0.17426928668024655), high=Score(precision=0.2742321826747394, recall=0.2533882547869698, fmeasure=0.1952496237132137)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=0.2906319407169865, recall=0.2818983162609439, fmeasure=0.22583014622277572), mid=Score(precision=0.3230903898664479, recall=0.318476461481069, fmeasure=0.2457615427700076), high=Score(precision=0.3603812548134879, recall=0.3530680555380189, fmeasure=0.2675111072618567))}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_preds = output\n",
    "fake_labels = final_df['abstract']\n",
    "rouge_raw_after_longformer = metric.compute(predictions=fake_preds, references=fake_labels)\n",
    "rouge_raw_after_longformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65493bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=0.5304662760648602, recall=0.4737862363035224, fmeasure=0.40511015522712024), mid=Score(precision=0.5822356246890301, recall=0.5426752454329447, fmeasure=0.4553252401818941), high=Score(precision=0.6350327296990234, recall=0.6155726919129928, fmeasure=0.5101201785281441)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=0.35351010968760116, recall=0.35858779218572306, fmeasure=0.2928480515224427), mid=Score(precision=0.4119071880165833, recall=0.4319318498862359, fmeasure=0.3519665219935322), high=Score(precision=0.46884581126593383, recall=0.506146407224723, fmeasure=0.41269201802948946)),\n",
       " 'rougeL': AggregateScore(low=Score(precision=0.434707134096158, recall=0.3975358048342975, fmeasure=0.33492842366069997), mid=Score(precision=0.48593552092048364, recall=0.4692854869830918, fmeasure=0.38958271049239834), high=Score(precision=0.5425383503826493, recall=0.5425236560156025, fmeasure=0.45324529150495757)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=0.5026897367710759, recall=0.460547224050765, fmeasure=0.38828376081122506), mid=Score(precision=0.5546698497427504, recall=0.5242803454472404, fmeasure=0.4401699590754458), high=Score(precision=0.6088607694015339, recall=0.5886083638203777, fmeasure=0.4883268896917123))}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_preds = output\n",
    "fake_labels = final_df['predicted_abstract']\n",
    "rouge_pred_after_longformer = metric.compute(predictions=fake_preds, references=fake_labels)\n",
    "rouge_pred_after_longformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5615c5ef",
   "metadata": {},
   "source": [
    "### pubmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d6a731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "with open('../csci-544-project/data/longformer_pubmed.txt') as f:\n",
    "    text = f.readline()\n",
    "    while text:\n",
    "        json_data = json.loads(text)\n",
    "        data.append(json_data)\n",
    "        text = f.readline()\n",
    "    final_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c344e99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>abstract</th>\n",
       "      <th>predicted_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>research on the implications of anxiety in pa...</td>\n",
       "      <td>anxiety affects quality of life in those livi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>small non - coding rnas include sirna , mirna...</td>\n",
       "      <td>small non - coding rnas ( mirnas ) are a clas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>objective : to evaluate the efficacy and safe...</td>\n",
       "      <td>\\n background. \\n the aim of the current stud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>congenital adrenal hyperplasia is a group of ...</td>\n",
       "      <td>background : congenital adrenal hyperplasia (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>objective(s):pentoxifylline is an immunomodul...</td>\n",
       "      <td>type 1 diabetes ( t1d ) results from the dest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>chondroblastoma is a rare , giant cell - rich...</td>\n",
       "      <td>chondroblastoma accounts for &lt; 1% of all prim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>backgroundsuicide is a grave public health is...</td>\n",
       "      <td>background : suicide is a grave public health...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>backgroundlow adherence to global initiative ...</td>\n",
       "      <td>background : copd is characterized by persist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>backgroundnephrotoxicity is the most clinical...</td>\n",
       "      <td>backgroundamphotericin b ( amb ), an amphoter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>the glycosylation abilities of snails deserve...</td>\n",
       "      <td>o - glycans have been found to play an import...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                           abstract  \\\n",
       "0    0   research on the implications of anxiety in pa...   \n",
       "1    1   small non - coding rnas include sirna , mirna...   \n",
       "2    2   objective : to evaluate the efficacy and safe...   \n",
       "3    3   congenital adrenal hyperplasia is a group of ...   \n",
       "4    4   objective(s):pentoxifylline is an immunomodul...   \n",
       "..  ..                                                ...   \n",
       "95  95   chondroblastoma is a rare , giant cell - rich...   \n",
       "96  96   backgroundsuicide is a grave public health is...   \n",
       "97  97   backgroundlow adherence to global initiative ...   \n",
       "98  98   backgroundnephrotoxicity is the most clinical...   \n",
       "99  99   the glycosylation abilities of snails deserve...   \n",
       "\n",
       "                                   predicted_abstract  \n",
       "0    anxiety affects quality of life in those livi...  \n",
       "1    small non - coding rnas ( mirnas ) are a clas...  \n",
       "2    \\n background. \\n the aim of the current stud...  \n",
       "3    background : congenital adrenal hyperplasia (...  \n",
       "4    type 1 diabetes ( t1d ) results from the dest...  \n",
       "..                                                ...  \n",
       "95   chondroblastoma accounts for < 1% of all prim...  \n",
       "96   background : suicide is a grave public health...  \n",
       "97   background : copd is characterized by persist...  \n",
       "98   backgroundamphotericin b ( amb ), an amphoter...  \n",
       "99   o - glycans have been found to play an import...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93d93534",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [03:48<00:00,  2.28s/it]\n"
     ]
    }
   ],
   "source": [
    "# using GPT-3 model with pubmed row text\n",
    "import os\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "openai.organization = \"org-dcppzQporJVCl0uhI8Tk67Xo\"\n",
    "openai.api_key = \"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\"\n",
    "engine_list = openai.Engine.list() \n",
    "#openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "output = []\n",
    "#final_output = []\n",
    "for i in tqdm(range(len(final_df))):\n",
    "    try:\n",
    "        tldr_tag = \"\\n tl;dr:\"\n",
    "        text =  str(final_df[\"abstract\"].iloc[i])+ tldr_tag\n",
    "        response = openai.Completion.create(\n",
    "          engine=\"curie\",\n",
    "          prompt=text,\n",
    "          temperature=0.5,\n",
    "          max_tokens=500,\n",
    "          top_p=1,\n",
    "          frequency_penalty=0.2,\n",
    "          presence_penalty=0\n",
    "        )\n",
    "        output.append(response[\"choices\"][0]['text'])\n",
    "    except:# if the token exceed the maximum tokens number in GPT-3 model,then just use first half text\n",
    "        tldr_tag = \"\\n tl;dr:\"\n",
    "        a = final_df[\"abstract\"].iloc[i][:int(len(final_df[\"abstract\"].iloc[i])/2)]\n",
    "        text = a+ tldr_tag\n",
    "        response = openai.Completion.create(\n",
    "          engine=\"curie\",\n",
    "          prompt=text,\n",
    "          temperature=0.5,\n",
    "          max_tokens=500,\n",
    "          top_p=1,\n",
    "          frequency_penalty=0.2,\n",
    "          presence_penalty=0\n",
    "        )\n",
    "        output.append(response[\"choices\"][0]['text'])\n",
    "#final_output.append(output)\n",
    "pred_df = pd.DataFrame()\n",
    "pred_df[\"summary\"] = output \n",
    "pred_df.to_csv(\"pubmed_before_longformer_summary_100.csv\",sep = ' ',index = False,header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "827720ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=0.5160825024558819, recall=0.3321556038813583, fmeasure=0.3139740826017568), mid=Score(precision=0.5684754402603172, recall=0.39428958277813364, fmeasure=0.3573277039675052), high=Score(precision=0.618798861044323, recall=0.4535894939321148, fmeasure=0.4002743799797062)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=0.315314979981466, recall=0.20540674599502148, fmeasure=0.1874786221400654), mid=Score(precision=0.36989487675104393, recall=0.2705093392438204, fmeasure=0.24035659617280736), high=Score(precision=0.4283063576095628, recall=0.33653339897808904, fmeasure=0.29019274811796186)),\n",
       " 'rougeL': AggregateScore(low=Score(precision=0.4058159368552749, recall=0.2582120954810843, fmeasure=0.23974934602064368), mid=Score(precision=0.4571002918417728, recall=0.315814528145686, fmeasure=0.28450282686956613), high=Score(precision=0.5111746272449081, recall=0.37239182315912245, fmeasure=0.32629618885112166)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=0.48154336944135306, recall=0.3151534247727707, fmeasure=0.29500635231551325), mid=Score(precision=0.5323516718400778, recall=0.3730583434934257, fmeasure=0.3369888190927861), high=Score(precision=0.5824354628595001, recall=0.43400993098953866, fmeasure=0.38363766154583284))}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_preds = output\n",
    "fake_labels = final_df['abstract']\n",
    "rouge_pubmed_raw_before_longformer = metric.compute(predictions=fake_preds, references=fake_labels)\n",
    "rouge_pubmed_raw_before_longformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35d9f3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [03:32<00:00,  2.13s/it]\n"
     ]
    }
   ],
   "source": [
    "# using GPT-3 model with pubmed pred of longformer\n",
    "import os\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "openai.organization = \"org-dcppzQporJVCl0uhI8Tk67Xo\"\n",
    "openai.api_key = \"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\"\n",
    "engine_list = openai.Engine.list() \n",
    "#openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "output = []\n",
    "#final_output = []\n",
    "for i in tqdm(range(len(final_df))):\n",
    "    try:\n",
    "        tldr_tag = \"\\n tl;dr:\"\n",
    "        text =  str(final_df[\"predicted_abstract\"].iloc[i])+ tldr_tag\n",
    "        response = openai.Completion.create(\n",
    "          engine=\"curie\",\n",
    "          prompt=text,\n",
    "          temperature=0.5,\n",
    "          max_tokens=500,\n",
    "          top_p=1,\n",
    "          frequency_penalty=0.2,\n",
    "          presence_penalty=0\n",
    "        )\n",
    "        output.append(response[\"choices\"][0]['text'])\n",
    "    except:# if the token exceed the maximum tokens number in GPT-3 model,then just use first half text\n",
    "        tldr_tag = \"\\n tl;dr:\"\n",
    "        a = final_df[\"predicted_abstract\"].iloc[i][:int(len(final_df[\"predicted_abstract\"].iloc[i])/2)]\n",
    "        text = a+ tldr_tag\n",
    "        response = openai.Completion.create(\n",
    "          engine=\"curie\",\n",
    "          prompt=text,\n",
    "          temperature=0.5,\n",
    "          max_tokens=500,\n",
    "          top_p=1,\n",
    "          frequency_penalty=0.2,\n",
    "          presence_penalty=0\n",
    "        )\n",
    "        output.append(response[\"choices\"][0]['text'])\n",
    "#final_output.append(output)\n",
    "pred_df = pd.DataFrame()\n",
    "pred_df[\"summary\"] = output \n",
    "pred_df.to_csv(\"pubmed_after_longformer_summary_100.csv\",sep = ' ',index = False,header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c727188d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=0.3797123807931195, recall=0.22273128378697904, fmeasure=0.21414028102432928), mid=Score(precision=0.42332284607104703, recall=0.26102968417081773, fmeasure=0.23880258432532572), high=Score(precision=0.463729300041353, recall=0.30502560078178775, fmeasure=0.2683008400956793)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=0.1059916754114016, recall=0.06406976268861651, fmeasure=0.05922953169601327), mid=Score(precision=0.1301288844385633, recall=0.08144877693782837, fmeasure=0.07323157171763009), high=Score(precision=0.16000852081979078, recall=0.10317540160338566, fmeasure=0.09430505165125866)),\n",
       " 'rougeL': AggregateScore(low=Score(precision=0.25052978020793404, recall=0.13386346514949546, fmeasure=0.13110548277926587), mid=Score(precision=0.28477748439638306, recall=0.15851733042269434, fmeasure=0.14750732535004835), high=Score(precision=0.3215720320118474, recall=0.18470292651648076, fmeasure=0.16885925914049127)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=0.3240144032587471, recall=0.18114304361334002, fmeasure=0.17728846207404036), mid=Score(precision=0.36547393797856254, recall=0.2181107925491534, fmeasure=0.19996835495543286), high=Score(precision=0.4052593460838847, recall=0.25296795502874064, fmeasure=0.22449584127246114))}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_preds = output\n",
    "fake_labels = final_df['abstract']\n",
    "rouge_pubmed_raw_after_longformer = metric.compute(predictions=fake_preds, references=fake_labels)\n",
    "rouge_pubmed_raw_after_longformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b20fe7cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=0.5190822193408541, recall=0.3157759787722036, fmeasure=0.2971947941229856), mid=Score(precision=0.5758139464460084, recall=0.3792696628584491, fmeasure=0.34623144520868687), high=Score(precision=0.6331641699217616, recall=0.45378584115700765, fmeasure=0.40085027046386706)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=0.29392474530510226, recall=0.20731776789534037, fmeasure=0.18900316543124512), mid=Score(precision=0.35119454538632855, recall=0.2754241621150259, fmeasure=0.24314296002819152), high=Score(precision=0.409821399089241, recall=0.3443718987166966, fmeasure=0.29871114094369533)),\n",
       " 'rougeL': AggregateScore(low=Score(precision=0.4070120506222097, recall=0.25415848084196974, fmeasure=0.2378080527688533), mid=Score(precision=0.46209548792261745, recall=0.3204893319683072, fmeasure=0.29183638432393433), high=Score(precision=0.5144549250289235, recall=0.3924479237851109, fmeasure=0.3457484189234962)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=0.452673297816959, recall=0.2773188847070821, fmeasure=0.2596543463683606), mid=Score(precision=0.5083556467326893, recall=0.34635624438256746, fmeasure=0.31296478563262753), high=Score(precision=0.5619094529485914, recall=0.41326670296232715, fmeasure=0.36878529859622766))}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_preds = output\n",
    "fake_labels = final_df['predicted_abstract']\n",
    "rouge_pubmed_pred_after_longformer = metric.compute(predictions=fake_preds, references=fake_labels)\n",
    "rouge_pubmed_pred_after_longformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "68bf4483",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "report_df = pd.DataFrame(columns = ['data_resource', 'raw_rough_1','raw_rough_2','raw_rough_L','longformer_rough_1','longformer_rough_2','longformer_rough_L'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ea8188f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv = {'data_resource':'arxiv', 'raw_rough_1':39.84,'raw_rough_2':29.68,'raw_rough_L':33.74,'longformer_rough_1':28.24,'longformer_rough_2':9.82,'longformer_rough_L':17.43}\n",
    "pubmed = {'data_resource':'pubmed', 'raw_rough_1':35.73,'raw_rough_2':24.04,'raw_rough_L':28.45,'longformer_rough_1':23.88,'longformer_rough_2':7.32,'longformer_rough_L':14.75}\n",
    "\n",
    "report_df = report_df.append(arxiv, ignore_index = True)\n",
    "report_df = report_df.append(pubmed, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68bc29ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_resource</th>\n",
       "      <th>raw_rough_1</th>\n",
       "      <th>raw_rough_2</th>\n",
       "      <th>raw_rough_L</th>\n",
       "      <th>longformer_rough_1</th>\n",
       "      <th>longformer_rough_2</th>\n",
       "      <th>longformer_rough_L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arxiv</td>\n",
       "      <td>39.84</td>\n",
       "      <td>29.68</td>\n",
       "      <td>33.74</td>\n",
       "      <td>28.24</td>\n",
       "      <td>9.82</td>\n",
       "      <td>17.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pubmed</td>\n",
       "      <td>35.73</td>\n",
       "      <td>24.04</td>\n",
       "      <td>28.45</td>\n",
       "      <td>23.88</td>\n",
       "      <td>7.32</td>\n",
       "      <td>14.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  data_resource  raw_rough_1  raw_rough_2  raw_rough_L  longformer_rough_1  \\\n",
       "0         arxiv        39.84        29.68        33.74               28.24   \n",
       "1        pubmed        35.73        24.04        28.45               23.88   \n",
       "\n",
       "   longformer_rough_2  longformer_rough_L  \n",
       "0                9.82               17.43  \n",
       "1                7.32               14.75  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81b3ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
