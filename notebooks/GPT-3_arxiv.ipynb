{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a6c563b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6497670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../csci-544-project/data/extraction-arxiv.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    final_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7d852f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions</th>\n",
       "      <th>references</th>\n",
       "      <th>predictions_joined</th>\n",
       "      <th>references_joined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[&lt;S&gt; [ approxerrorthm ] under assumption [ ass...</td>\n",
       "      <td>[&lt;S&gt; additive models play an important role in...</td>\n",
       "      <td>[ approxerrorthm ] under assumption [ assumpti...</td>\n",
       "      <td>additive models play an important role in semi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[&lt;S&gt; .[table : data - single ] summary of sing...</td>\n",
       "      <td>[&lt;S&gt; we have studied the leptonic decay @xmath...</td>\n",
       "      <td>.[table : data - single ] summary of single - ...</td>\n",
       "      <td>we have studied the leptonic decay @xmath0 , v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[&lt;S&gt; two chaotic attractors emerge with @xmath...</td>\n",
       "      <td>[&lt;S&gt; in 84 , 258 ( 2000 ) , mateos conjectured...</td>\n",
       "      <td>two chaotic attractors emerge with @xmath9 ( b...</td>\n",
       "      <td>in 84 , 258 ( 2000 ) , mateos conjectured that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[&lt;S&gt; [ sixteen ] can be replaced by @xmath90 w...</td>\n",
       "      <td>[&lt;S&gt; the effect of a random phase diffuser on ...</td>\n",
       "      <td>[ sixteen ] can be replaced by @xmath90 where ...</td>\n",
       "      <td>the effect of a random phase diffuser on fluct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[&lt;S&gt; the soliton equation of motion is obtaine...</td>\n",
       "      <td>[&lt;S&gt; with a special intention of clarifying th...</td>\n",
       "      <td>the soliton equation of motion is obtained fro...</td>\n",
       "      <td>with a special intention of clarifying the und...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[&lt;S&gt; @xmath16 corresponds to the horizontal ax...</td>\n",
       "      <td>[&lt;S&gt; we improve the currently known thresholds...</td>\n",
       "      <td>@xmath16 corresponds to the horizontal axis an...</td>\n",
       "      <td>we improve the currently known thresholds for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[&lt;S&gt; this psychological model partitions the h...</td>\n",
       "      <td>[&lt;S&gt; synaptic memory is considered to be the m...</td>\n",
       "      <td>this psychological model partitions the human ...</td>\n",
       "      <td>synaptic memory is considered to be the main e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[&lt;S&gt; it exploits the pose relationship that ca...</td>\n",
       "      <td>[&lt;S&gt; this paper investigates , using prior sha...</td>\n",
       "      <td>it exploits the pose relationship that can be ...</td>\n",
       "      <td>this paper investigates , using prior shape mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[&lt;S&gt; of particular interest are systems which ...</td>\n",
       "      <td>[&lt;S&gt; long time coverage and high radial veloci...</td>\n",
       "      <td>of particular interest are systems which host ...</td>\n",
       "      <td>long time coverage and high radial velocity pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[&lt;S&gt; we derive the first variation @xmath66 by...</td>\n",
       "      <td>[&lt;S&gt; we study equilibrium configurations of sw...</td>\n",
       "      <td>we derive the first variation @xmath66 by subs...</td>\n",
       "      <td>we study equilibrium configurations of swarmin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[&lt;S&gt; ( b ) the @xmath27 distribution for candi...</td>\n",
       "      <td>[&lt;S&gt; i discuss new results on absolute branchi...</td>\n",
       "      <td>( b ) the @xmath27 distribution for candidates...</td>\n",
       "      <td>i discuss new results on absolute branching ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[&lt;S&gt; approximate fitting formulae may be deriv...</td>\n",
       "      <td>[&lt;S&gt; cut - sky orthogonal mode analyses of the...</td>\n",
       "      <td>approximate fitting formulae may be derived to...</td>\n",
       "      <td>cut - sky orthogonal mode analyses of the @xma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          predictions  \\\n",
       "0   [<S> [ approxerrorthm ] under assumption [ ass...   \n",
       "1   [<S> .[table : data - single ] summary of sing...   \n",
       "2   [<S> two chaotic attractors emerge with @xmath...   \n",
       "3   [<S> [ sixteen ] can be replaced by @xmath90 w...   \n",
       "4   [<S> the soliton equation of motion is obtaine...   \n",
       "5   [<S> @xmath16 corresponds to the horizontal ax...   \n",
       "7   [<S> this psychological model partitions the h...   \n",
       "8   [<S> it exploits the pose relationship that ca...   \n",
       "9   [<S> of particular interest are systems which ...   \n",
       "10  [<S> we derive the first variation @xmath66 by...   \n",
       "11  [<S> ( b ) the @xmath27 distribution for candi...   \n",
       "12  [<S> approximate fitting formulae may be deriv...   \n",
       "\n",
       "                                           references  \\\n",
       "0   [<S> additive models play an important role in...   \n",
       "1   [<S> we have studied the leptonic decay @xmath...   \n",
       "2   [<S> in 84 , 258 ( 2000 ) , mateos conjectured...   \n",
       "3   [<S> the effect of a random phase diffuser on ...   \n",
       "4   [<S> with a special intention of clarifying th...   \n",
       "5   [<S> we improve the currently known thresholds...   \n",
       "7   [<S> synaptic memory is considered to be the m...   \n",
       "8   [<S> this paper investigates , using prior sha...   \n",
       "9   [<S> long time coverage and high radial veloci...   \n",
       "10  [<S> we study equilibrium configurations of sw...   \n",
       "11  [<S> i discuss new results on absolute branchi...   \n",
       "12  [<S> cut - sky orthogonal mode analyses of the...   \n",
       "\n",
       "                                   predictions_joined  \\\n",
       "0   [ approxerrorthm ] under assumption [ assumpti...   \n",
       "1   .[table : data - single ] summary of single - ...   \n",
       "2   two chaotic attractors emerge with @xmath9 ( b...   \n",
       "3   [ sixteen ] can be replaced by @xmath90 where ...   \n",
       "4   the soliton equation of motion is obtained fro...   \n",
       "5   @xmath16 corresponds to the horizontal axis an...   \n",
       "7   this psychological model partitions the human ...   \n",
       "8   it exploits the pose relationship that can be ...   \n",
       "9   of particular interest are systems which host ...   \n",
       "10  we derive the first variation @xmath66 by subs...   \n",
       "11  ( b ) the @xmath27 distribution for candidates...   \n",
       "12  approximate fitting formulae may be derived to...   \n",
       "\n",
       "                                    references_joined  \n",
       "0   additive models play an important role in semi...  \n",
       "1   we have studied the leptonic decay @xmath0 , v...  \n",
       "2   in 84 , 258 ( 2000 ) , mateos conjectured that...  \n",
       "3   the effect of a random phase diffuser on fluct...  \n",
       "4   with a special intention of clarifying the und...  \n",
       "5   we improve the currently known thresholds for ...  \n",
       "7   synaptic memory is considered to be the main e...  \n",
       "8   this paper investigates , using prior shape mo...  \n",
       "9   long time coverage and high radial velocity pr...  \n",
       "10  we study equilibrium configurations of swarmin...  \n",
       "11  i discuss new results on absolute branching ra...  \n",
       "12  cut - sky orthogonal mode analyses of the @xma...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1022e0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [52:08<00:00,  3.13s/it] \n"
     ]
    }
   ],
   "source": [
    "# full data, The time of processing all 119924 paper is 250 days :), so run first 1000 paper\n",
    "# Pubmed after extraction first 1000 paper\n",
    "import os\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "openai.organization = \"org-Kd6j4eVV6enxYcFJCoirAG9U\"\n",
    "openai.api_key = \"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\"\n",
    "engine_list = openai.Engine.list() \n",
    "#openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "output = []\n",
    "#final_output = []\n",
    "for i in tqdm(range(1000)):\n",
    "    try:\n",
    "        tldr_tag = \"\\n tl;dr:\"\n",
    "        text =  str(final_df[\"references_joined\"].iloc[i])+ tldr_tag\n",
    "        response = openai.Completion.create(\n",
    "          engine=\"curie\",\n",
    "          prompt=text,\n",
    "          temperature=0.5,\n",
    "          max_tokens=500,\n",
    "          top_p=1,\n",
    "          frequency_penalty=0.2,\n",
    "          presence_penalty=0\n",
    "        )\n",
    "        output.append(response[\"choices\"][0]['text'])\n",
    "    except:# if the token exceed the maximum tokens number in GPT-3 model,then just use first half text\n",
    "        tldr_tag = \"\\n tl;dr:\"\n",
    "        a = final_df[\"references_joined\"].iloc[i][:int(len(final_df[\"references_joined\"].iloc[i])/2.7)]\n",
    "        text = a+ tldr_tag\n",
    "        response = openai.Completion.create(\n",
    "          engine=\"curie\",\n",
    "          prompt=text,\n",
    "          temperature=0.5,\n",
    "          max_tokens=500,\n",
    "          top_p=1,\n",
    "          frequency_penalty=0.2,\n",
    "          presence_penalty=0\n",
    "        )\n",
    "        output.append(response[\"choices\"][0]['text'])\n",
    "#final_output.append(output)\n",
    "pred_df = pd.DataFrame()\n",
    "pred_df[\"summary\"] = output \n",
    "pred_df.to_csv(\"arxiv_before_extraction_summary_1000.csv\",sep = ' ',index = False,header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2582ae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_metric\n",
    "metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd910645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=0.48303912142176264, recall=0.6100104069803629, fmeasure=0.4491357122022853), mid=Score(precision=0.5011460639863834, recall=0.6286977568514927, fmeasure=0.46450386782935504), high=Score(precision=0.5189043708395678, recall=0.649035621718375, fmeasure=0.4811067750640798)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=0.36471874202067467, recall=0.4800704717370082, fmeasure=0.354239072090012), mid=Score(precision=0.38449560048844367, recall=0.5031366810975006, fmeasure=0.37354316772266877), high=Score(precision=0.4048756102941341, recall=0.5279411533967993, fmeasure=0.39295309373482856)),\n",
       " 'rougeL': AggregateScore(low=Score(precision=0.41425885606577356, recall=0.5295044800201953, fmeasure=0.38988212935308086), mid=Score(precision=0.43348118766333343, recall=0.5508824506539802, fmeasure=0.40797227751708226), high=Score(precision=0.4529506806954434, recall=0.573304335441046, fmeasure=0.4264468404003554)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=0.41887986884485245, recall=0.5442696317543718, fmeasure=0.3979680937544927), mid=Score(precision=0.4372914353005076, recall=0.5653730211880197, fmeasure=0.41480757433682314), high=Score(precision=0.45629355353534423, recall=0.5871628706178472, fmeasure=0.4323877257204466))}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw text of papers\n",
    "fake_preds = output\n",
    "fake_labels = final_df['references_joined'].head(1000)\n",
    "metric.compute(predictions=fake_preds, references=fake_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dadc7190",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [49:39<00:00,  2.98s/it] \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "openai.organization = \"org-5aaOVFKkT7XKoqbOEzZj8Law\"\n",
    "openai.api_key = \"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\"\n",
    "engine_list = openai.Engine.list() \n",
    "#openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "output = []\n",
    "#final_output = []\n",
    "for i in tqdm(range(1000)):\n",
    "    try:\n",
    "        tldr_tag = \"\\n tl;dr:\"\n",
    "        text =  str(final_df[\"predictions_joined\"].iloc[i])+ tldr_tag\n",
    "        response = openai.Completion.create(\n",
    "          engine=\"curie\",\n",
    "          prompt=text,\n",
    "          temperature=0.5,\n",
    "          max_tokens=500,\n",
    "          top_p=1,\n",
    "          frequency_penalty=0.2,\n",
    "          presence_penalty=0\n",
    "        )\n",
    "        output.append(response[\"choices\"][0]['text'])\n",
    "    except:# if the token exceed the maximum tokens number in GPT-3 model,then just use first 1/60 text\n",
    "        tldr_tag = \"\\n tl;dr:\"\n",
    "        a = final_df[\"predictions_joined\"].iloc[i][:int(len(final_df[\"predictions_joined\"].iloc[i])/60)]\n",
    "        text = a+ tldr_tag\n",
    "        response = openai.Completion.create(\n",
    "          engine=\"curie\",\n",
    "          prompt=text,\n",
    "          temperature=0.5,\n",
    "          max_tokens=500,\n",
    "          top_p=1,\n",
    "          frequency_penalty=0.2,\n",
    "          presence_penalty=0\n",
    "        )\n",
    "        output.append(response[\"choices\"][0]['text'])\n",
    "#final_output.append(output)\n",
    "pred_df = pd.DataFrame()\n",
    "pred_df[\"summary\"] = output \n",
    "pred_df.to_csv(\"arxiv_after_extraction_summary_1000.csv\",sep = ' ',index = False,header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "255327ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': AggregateScore(low=Score(precision=0.270598191997629, recall=0.25034230047705847, fmeasure=0.20650631880937223), mid=Score(precision=0.2833082121270035, recall=0.2595344167053628, fmeasure=0.21240777478921904), high=Score(precision=0.29498960049556866, recall=0.26868060622414414, fmeasure=0.21847745003804783)),\n",
       " 'rouge2': AggregateScore(low=Score(precision=0.061446339939019386, recall=0.05113901776257276, fmeasure=0.04320094220514521), mid=Score(precision=0.06625842332783072, recall=0.05448025279424188, fmeasure=0.04574238986332271), high=Score(precision=0.07155250930877914, recall=0.058102462374027386, fmeasure=0.04846681564191315)),\n",
       " 'rougeL': AggregateScore(low=Score(precision=0.17832752773831706, recall=0.15963836055515687, fmeasure=0.13076143162058912), mid=Score(precision=0.186422055363512, recall=0.16491720842903265, fmeasure=0.13383144889100504), high=Score(precision=0.19532563944085674, recall=0.17031308704703768, fmeasure=0.13704527399511154)),\n",
       " 'rougeLsum': AggregateScore(low=Score(precision=0.17516817352601943, recall=0.15866038285657974, fmeasure=0.1289995315650063), mid=Score(precision=0.18392367642173169, recall=0.16448549793813477, fmeasure=0.1324356162148959), high=Score(precision=0.19193877060034806, recall=0.17018633615778886, fmeasure=0.1358977361608779))}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_preds = output\n",
    "fake_labels = final_df['references_joined'].head(1000)\n",
    "metric.compute(predictions=fake_preds, references=fake_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "706eaa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_df = pd.DataFrame(columns = ['data_resource','data_num', 'raw_rough_1','raw_rough_2','raw_rough_L','extraction_rough_1','extraction_rough_2','extraction_rough_L'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2278329",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv = {'data_resource':'arxiv', 'data_num':1000,'raw_rough_1':46.45,'raw_rough_2':37.35,'raw_rough_L':40.80,'extraction_rough_1':21.24,'extraction_rough_2':4.57,'extraction_rough_L':13.38}\n",
    "\n",
    "report_df = report_df.append(arxiv, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "02bd82af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_resource</th>\n",
       "      <th>data_num</th>\n",
       "      <th>raw_rough_1</th>\n",
       "      <th>raw_rough_2</th>\n",
       "      <th>raw_rough_L</th>\n",
       "      <th>extraction_rough_1</th>\n",
       "      <th>extraction_rough_2</th>\n",
       "      <th>extraction_rough_L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arxiv</td>\n",
       "      <td>1000</td>\n",
       "      <td>46.45</td>\n",
       "      <td>37.35</td>\n",
       "      <td>40.8</td>\n",
       "      <td>21.24</td>\n",
       "      <td>4.57</td>\n",
       "      <td>13.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  data_resource data_num  raw_rough_1  raw_rough_2  raw_rough_L  \\\n",
       "0         arxiv     1000        46.45        37.35         40.8   \n",
       "\n",
       "   extraction_rough_1  extraction_rough_2  extraction_rough_L  \n",
       "0               21.24                4.57               13.38  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca2ba4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
